{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL_11 개체명 인식(Named Entity Recognition).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bye23mj/suanLee/blob/main/NL_11_%EA%B0%9C%EC%B2%B4%EB%AA%85_%EC%9D%B8%EC%8B%9D(Named_Entity_Recognition).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV70fimDW_-G"
      },
      "source": [
        "# 개체명 인식(Named Entity Recognition)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWA304rM5v8A"
      },
      "source": [
        "* 개체명 인식은 텍스트에서 이름을 가진 개체를 인식하는 기술      \n",
        "* 가령, '철수와 영희는 밥을 먹었다'에서 이름과 사물을 추출하는 개체명 인식 모델 결과 \n",
        "\n",
        "  철수 - 이름    \n",
        "  영희 - 이름    \n",
        "  밥 - 사물"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TwymWiS5fQs"
      },
      "source": [
        "## 개체명 인식 - NLTK\n",
        "\n",
        "* https://wikidocs.net/30682"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WClqugy-7LM4"
      },
      "source": [
        "* `nltk` 라이브러리에서는 미리 학습된 개체명 인식 모델을 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VP0CghXeLY-"
      },
      "source": [
        "### 라이브러리 준비"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "Gm51HqPHC4HH",
        "outputId": "b91e2202-ef76-4df0-8900-25c42600d80e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.61.129.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.61.129.82:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.129.82:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.61.129.82:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n",
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovXXNeMb7Xcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a612dc-7a85-4049-b3d7-dbfd5c3cd0b8"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lxskxmeQJU"
      },
      "source": [
        "### 토큰화 및 품사 태깅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mPuhBfs5qrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ebbac7-e9d3-4cf2-8687-c3281fcae025"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "sentence = \"James is working at Disney in London\"\n",
        "sentence = pos_tag(word_tokenize(sentence))\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('James', 'NNP'), ('is', 'VBZ'), ('working', 'VBG'), ('at', 'IN'), ('Disney', 'NNP'), ('in', 'IN'), ('London', 'NNP')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DZP3vVveYGs"
      },
      "source": [
        "### 개체명 인식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuDJ4Ur47Gzw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81915cd3-776b-43f7-aaad-1b32ca5f6e91"
      },
      "source": [
        "sentence = ne_chunk(sentence)\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  (PERSON James/NNP)\n",
            "  is/VBZ\n",
            "  working/VBG\n",
            "  at/IN\n",
            "  (ORGANIZATION Disney/NNP)\n",
            "  in/IN\n",
            "  (GPE London/NNP))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvSriP226tSZ"
      },
      "source": [
        "## 개체명 인식 - LSTM\n",
        "\n",
        "* https://wikidocs.net/24682"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOoJbTJC7xLC"
      },
      "source": [
        "* 사용자가 제공되고 있는 개체명 인식 모델과는 다른 개체명을 정의해 사용하는 것이 필요할 수 있음\n",
        "* 직접 개체명 인식 모델을 구성해 학습하고 사용할 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TZcsoHWee4F"
      },
      "source": [
        "### 라이브러리 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3Pmu8QG64cK"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDgF2DTOeih2"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZKtNz4OwI1C"
      },
      "source": [
        "* 공개된 개체명 인식 데이터셋을 이용\n",
        "  + https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt\n",
        "* 해당 데이터는 단어-개체명 형식으로 이루어져 있으므로 이를 가공해 데이터셋을 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXnAk3SFC87h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd50563e-5586-4be3-ea35-656056b6bf64"
      },
      "source": [
        "tagged_sentences = []\n",
        "sentence = []\n",
        "\n",
        "with urllib.request.urlopen('https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt') as f:\n",
        "  for line in f:\n",
        "    line = line.decode('utf-8')\n",
        "    if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
        "      if len(sentence) > 0:\n",
        "        tagged_sentences.append(sentence)\n",
        "        sentence = []\n",
        "      continue\n",
        "    splits = line.strip().split(' ')\n",
        "    word = splits[0].lower()\n",
        "    sentence.append([word, splits[-1]])\n",
        "\n",
        "print(len(tagged_sentences))\n",
        "print(tagged_sentences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14041\n",
            "[['eu', 'B-ORG'], ['rejects', 'O'], ['german', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['british', 'B-MISC'], ['lamb', 'O'], ['.', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3VOetBewLN"
      },
      "source": [
        "### 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HTqk1LJwcFm"
      },
      "source": [
        "* 단어와 개체명 태그를 분리해서 데이터를 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvsvx1q8C9BP"
      },
      "source": [
        "sentences, ner_tags = [], []\n",
        "\n",
        "for tagged_sentences in tagged_sentences:\n",
        "  sentence, tag_info = zip(*tagged_sentences)\n",
        "  sentences.append(list(sentence))\n",
        "  ner_tags.append(list(tag_info))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flb_gBeGwqdA"
      },
      "source": [
        "* 정제 및 빈도 수가 높은 상위 단어들만 추출하기 위해 토큰화 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIFAktdLDJZj"
      },
      "source": [
        "max_words = 4000\n",
        "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
        "src_tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "tar_tokenizer = Tokenizer()\n",
        "tar_tokenizer.fit_on_texts(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsOP0gUdDL6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a2e604d-5e53-4bf7-af88-d0073aec37dc"
      },
      "source": [
        "vocab_size = max_words\n",
        "tag_size = len(tar_tokenizer.word_index) + 1\n",
        "\n",
        "print(vocab_size)\n",
        "print(tag_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5dr-rJMxFV1"
      },
      "source": [
        "* 데이터를 학습에 활용하기 위해 데이터를 배열로 변환\n",
        "* 해당 작업은 토큰화 툴의 `texts_to_sequences()`를 통해 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTUzeqW-DNdv"
      },
      "source": [
        "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
        "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klstjOu4xQmL"
      },
      "source": [
        "* 학습에 투입할 때는 동일한 길이를 가져야 하므로, 지정해둔 최대 길이에 맞춰 모든 데이터를 동일한 길이로 맞춰줌\n",
        "* 일반적으로 길이를 맞출 때는 모자란 길이만큼 0을 추가\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwvNulj2DO9Z"
      },
      "source": [
        "max_len = 70\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
        "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYK8UDkxxefx"
      },
      "source": [
        "* 훈련, 실험 데이터 분리 및 원 핫 인코딩을 시행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVtO_DApDR64"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=111)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=tag_size)\n",
        "y_test = to_categorical(y_test, num_classes=tag_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGqT1AGPxjKV"
      },
      "source": [
        "* 최종적으로 생성된 데이터셋의 크기는 다음과 같음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxrX6hkIDTU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa84ca7-3064-4ff1-de35-63f21e23ae29"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11232, 70)\n",
            "(11232, 70, 10)\n",
            "(2809, 70)\n",
            "(2809, 70, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8h9L6H-e0Vl"
      },
      "source": [
        "### 모델 구축 및 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMLRWTzOxzf5"
      },
      "source": [
        "* 모델 구축에는 `keras`를 이용\n",
        "* 해당 작업에 필요한 함수들을 추가로 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQzpED-KDW3f"
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
        "#from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0r8yR7nx84S"
      },
      "source": [
        "모델의 구성\n",
        "\n",
        "1. 입력을 실수 벡터로 임베딩\n",
        "2. 양방향 LSTM 구성\n",
        "3. Dense layer를 통한 각 태그에 속할 확률 예측\n",
        "\n",
        "`TimeDistributed`는 상위 layer의 출력이 step에 따라 여러 개로 출력되어 이를 적절하게 분배해주는 역할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0VhAso8DYc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072ee66f-7afd-4469-cb78-aa610c953660"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
        "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 70, 128)           512000    \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 70, 512)          788480    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 70, 10)           5130      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,305,610\n",
            "Trainable params: 1,305,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrpUv_mxyqzR"
      },
      "source": [
        "* 모델 컴파일 및 학습 진행, 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARUqZJwHDZuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334424c4-468a-4b8e-a49a-bf6559de738c"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=3, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "88/88 [==============================] - 31s 274ms/step - loss: 0.0974 - accuracy: 0.8771 - val_loss: 0.0412 - val_accuracy: 0.9431\n",
            "Epoch 2/3\n",
            "88/88 [==============================] - 21s 241ms/step - loss: 0.0321 - accuracy: 0.9546 - val_loss: 0.0293 - val_accuracy: 0.9591\n",
            "Epoch 3/3\n",
            "88/88 [==============================] - 21s 241ms/step - loss: 0.0226 - accuracy: 0.9669 - val_loss: 0.0272 - val_accuracy: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5289770750>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVQsKQwlDfag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f987fc40-7eba-4405-bf16-8f3bd9359850"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 5s 54ms/step - loss: 0.0272 - accuracy: 0.9637\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02719312533736229, 0.9637476205825806]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO13spS4fA27"
      },
      "source": [
        "### 학습한 모델을 통한 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeLrlYTOyy3P"
      },
      "source": [
        "* 예측을 확인하기 위해서 인덱스를 단어로 변환해줄 사전이 필요\n",
        "* 사전은 토큰화 툴의 사전을 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQx8MLCZvdI0"
      },
      "source": [
        "idx2word = src_tokenizer.index_word\n",
        "idx2ner = tar_tokenizer.index_word\n",
        "idx2ner[0] = 'PAD'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4EQgmTIzBHp"
      },
      "source": [
        "* 예측 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsHL9I4yDgpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ecc10f-2a44-4d42-a725-2d1a97ea0284"
      },
      "source": [
        "i = 40\n",
        "y_predicted = model.predict(np.array([X_test[i]]))\n",
        "y_predicted = np.argmax(y_predicted, axis=-1)\n",
        "true = np.argmax(y_test[i], -1)\n",
        "\n",
        "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
        "print(\"-\" * 34)\n",
        "\n",
        "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
        "  if w != 0:\n",
        "    print(\"{:17}: {:7} {}\".format(idx2word[w], idx2ner[t].upper(), idx2ner[pred].upper()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어             |실제값  |예측값\n",
            "----------------------------------\n",
            "\"                : O       O\n",
            "i                : O       O\n",
            "will             : O       O\n",
            "no               : O       O\n",
            "longer           : O       O\n",
            "be               : O       O\n",
            "deputy           : O       O\n",
            "by               : O       O\n",
            "the              : O       O\n",
            "time             : O       O\n",
            "the              : O       O\n",
            "film             : O       O\n",
            "opens            : O       O\n",
            ",                : O       O\n",
            "\"                : O       O\n",
            "he               : O       O\n",
            "said             : O       O\n",
            "in               : O       O\n",
            "a                : O       O\n",
            "OOV              : O       O\n",
            "interview        : O       O\n",
            ".                : O       O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\""
      ],
      "metadata": {
        "id": "uMM2t6niGMfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}