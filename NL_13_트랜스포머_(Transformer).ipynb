{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL_13 트랜스포머 (Transformer).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bye23mj/suanLee/blob/main/NL_13_%ED%8A%B8%EB%9E%9C%EC%8A%A4%ED%8F%AC%EB%A8%B8_(Transformer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PQSnsGeA2OH"
      },
      "source": [
        "# 트랜스포머 (Transformer)\n",
        "\n",
        "* 참고: https://wikidocs.net/31379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbQ-h_XxBAiq"
      },
      "source": [
        "* attention mechanism은 seq2seq의 입력 시퀀스 정보 손실을 보정해주기 위해 사용됨\n",
        "* attention mechanism을 보정 목적이 아닌, 인코더와 디코더로 구성한 모델이 바로 트랜스포머\n",
        "* 트랜스포머는 RNN을 사용하지 않고 인코더와 디코더를 설계하였으며, 성능도 RNN보다 우수함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiFPIdUBBS2"
      },
      "source": [
        "## 포지셔널 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLqHf_4SEWoa"
      },
      "source": [
        "* 기존의 RNN은 단어의 위치를 따라 순차적으로 입력받아 단어의 위치정보를 활용할 수 있었음\n",
        "* 트랜스포머의 경우, RNN을 활용하지 않았기 때문에 단어의 위치정보를 다른 방식으로 줄 필요가 있음\n",
        "* 이를 위해 **각 단어의 임베딩 벡터에 위치 정보들을 더하게 되는데** 이를 포지셔널 인코딩이라 함\n",
        "* 보통 포지셔널 인코딩은 sin, cos을 이용하여 계산"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szOULdVwxpVj",
        "outputId": "9844d26a-0028-4caa-8939-78753008f022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiO5c_HIFBAk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def Positional_encoding(dim, sentence_length):\n",
        "  encoded_vec = np.array([pos / np.power(10000, 2 * i / dim) for pos in range(sentence_length) for i in range(dim)])\n",
        "  encoded_vec[::2] = np.sin(encoded_vec[::2])\n",
        "  encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n",
        "  return tf.constant(encoded_vec.reshape([sentence_length, dim]), dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "099gUUxhAgy3"
      },
      "source": [
        "## 레이어 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCdips98yPuH"
      },
      "source": [
        "*  레이어 정규화에서는 텐서의 마지막 차원에 대해 평균과 분산을 구하고, 이 값을 통해 값을 정규화함\n",
        "*  해당 정규화를 각 층의 연결에 편리하게 적용하기 위해 함수화한 `sublayer_connection()`을 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJjxF86Aeg3"
      },
      "source": [
        "def layer_norm(inputs, eps=1e-6):\n",
        "  feature_shape = inputs.get_shape()[-1:]\n",
        "  mean = tf.keras.backend.mean(inputs, [-1], keepdims=True)\n",
        "  std = tf.keras.backend.std(inputs, [-1], keepdims=True)\n",
        "  beta = tf.Variable(tf.zeros(feature_shape), trainable=False)\n",
        "  gamma = tf.Variable(tf.ones(feature_shape), trainable=False)\n",
        "  return gamma * (inputs - mean) / (std + eps) + beta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km9ORxIun-MU"
      },
      "source": [
        "def sublayer_connection(inputs, sublayer, dropout=0.2):\n",
        "  outputs = layer_norm(inputs + tf.keras.layers.Dropout(dropout)(sublayer))\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppb7IxJ3diMC"
      },
      "source": [
        "## 어텐션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JaU6MHgy9V2"
      },
      "source": [
        "\n",
        "\n",
        "*   트랜스포머 모델의 핵심이 되는 부분\n",
        "*   트랜스포머에서는 multi-head attention과 self attention이라는 개념을 사용\n",
        "  1.   multi-head attention\n",
        "      * 디코더가 가지는 차원을 나누어 병렬로 어텐션을 진행\n",
        "      *  마지막엔 병렬로 각 진행해 얻은 어텐션 헤드를 모두 연결\n",
        "      * 이로 인해 다양한 시각에서 정보를 수집할 수 있는 효과를 얻음\n",
        "  2.   self attention\n",
        "      *   일반적인 어텐션의 경우, 특정 시점의 디코더 은닉상태와 모든 시점의 인코더 은닉상태를 활용\n",
        "      *   이는 입력 문장과 다른 문장에 존재하는 단어간의 어텐션을 의미함\n",
        "      *   반면 self attention은 은닉 상태를 동일하게 하여 어텐션을 진행\n",
        "      *   이는 입력 문장 내 단어간의 어텐션을 의미함\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   트랜스포머 제안 논문에서는 scaled-dot product attention을 활용해 모델을 작성함\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRyL0KDXi6ej"
      },
      "source": [
        "### scaled-dot product attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HtmcgRR3Cr-"
      },
      "source": [
        "* scaled-dot product attention은 앞서 학습한 dot product attention과 거의 유사함\n",
        "* 단 attention을 진행할 때 어텐션 스코어를 계산할 때 내적 값을 정규화\n",
        "* 트랜스포머에서는 정규화할 때 K 벡터(=디코더 셀의 은닉 상태)의 차원을 루트를 취한 값을 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALEMzi4fdiSQ"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, masked=False):\n",
        "  key_dim_size = float(key.get_shape().as_list()[-1])\n",
        "  key = tf.transpose(key, perm=[0, 2, 1])\n",
        "\n",
        "  outputs = tf.matmul(query , key) / tf.sqrt(key_dim_size)\n",
        "\n",
        "  if masked:\n",
        "    diag_vals = tf.ones_like(outputs[0, :, :])\n",
        "    tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense()\n",
        "    masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1])\n",
        "    paddings = tf.ones_like(masks)*(-2**30)\n",
        "    outputs= tf.where(tf.equal(masks, 0), paddings, outputs)\n",
        "\n",
        "  attension_map = tf.nn.softmax(outputs)\n",
        "  return tf.matmul(attension_map, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr20BxvVi-8b"
      },
      "source": [
        "### multi-head attention 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb5qflUH14-H"
      },
      "source": [
        "* multi-head attention의 구현 과정\n",
        "  1. query, key, value에 해당하는 값을 받고, 해당 값에 해당하는 행렬 생성\n",
        "  2. 생성된 행렬들을 heads에 해당하는 수만큼 분리\n",
        "  3. 분리한 행렬들에 대해 각각 어텐션을 수행\n",
        "  4. 각 어텐션 결과들을 연결해 최종 어텐션 결과 생성\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooc3FAdQi_Gz"
      },
      "source": [
        "def multi_head_attention(query, key, value, num_units, heads, masked=False):\n",
        "  query = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(query)\n",
        "  key = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(key)\n",
        "  value = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(value)\n",
        "\n",
        "  query = tf.concat(tf.split(query, heads, axis=-1), axis=0)\n",
        "  key = tf.concat(tf.split(key, heads, axis=-1), axis=0)\n",
        "  value = tf.concat(tf.split(value, heads, axis=-1), axis=0)\n",
        "\n",
        "  attention_map = scaled_dot_product_attention(query, key, value, masked)\n",
        "  attn_outputs = tf.concat(tf.split(attention_map, heads, axis=0), axis=-1)\n",
        "  attn_outputs = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(attn_outputs)\n",
        "\n",
        "  return attn_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Zn5-fYITD4"
      },
      "source": [
        "## 포지션-와이즈 피드 포워드 신경망"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxeG2xvo3ZN"
      },
      "source": [
        "\n",
        "\n",
        "*   multi-head attention의 결과인 행렬을 입력받아 연산\n",
        "*   일반적인 완전 연결 신경망(Dense layer)를 사용\n",
        "*   position-wise FFNN은 인코더와 디코더에 모두 존재\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tSFd5OaITJ0"
      },
      "source": [
        "def feed_forward(inputs, num_units):\n",
        "  feature_shape = inputs.get_shape()[-1]\n",
        "  inner_layer = tf.keras.layers.Dense(num_units, activation=tf.nn.relu)(inputs)\n",
        "  outputs = tf.keras.layers.Dense(feature_shape)(inner_layer)\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuccViYgBK6v"
      },
      "source": [
        "## 인코더\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3MH0n1JVLz"
      },
      "source": [
        "* 인코더는 하나의 어텐션을 사용\n",
        "  + encoder self-attention (multi-head self-attention과 동일)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5T0pzBoAnn3"
      },
      "source": [
        "def encoder_module(inputs, model_dim, ffn_dim, heads):\n",
        "  self_attn = sublayer_connection(inputs, multi_head_attention(inputs, inputs, inputs, model_dim, heads))\n",
        "  outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "  return outputs\n",
        "\n",
        "def encoder(inputs, model_dim, ffn_dim, heads, num_layers):\n",
        "  outputs = inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_module(outputs, model_dim, ffn_dim, heads)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcgHRcTEBQqg"
      },
      "source": [
        "## 디코더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNj-6FLQwT4-"
      },
      "source": [
        "* 디코더는 다음과 같은 구성의 반복으로 이루어짐\n",
        "  1. masked decoder self-attention\n",
        "  2. encoder-decoder attention\n",
        "  3. position-wise FFNN\n",
        "\n",
        "* 디코더에서는 2종류의 어텐션을 사용\n",
        "  1.   masked decoder self-attention\n",
        "    *   디코더에서는 인코더와는 달리 순차적으로 결과를 만들어 내야하기 때문에 다른 어텐션 방법을 사용함\n",
        "    *   디코더 예측 시점 이후의 위치에 attention을 할 수 없도록 masking 처리\n",
        "    *   결국 예측 시점에서 예측은 미리 알고 있는 위치까지만의 결과에 의존\n",
        "  2.   encoder-decoder attention\n",
        "    *   앞서 설명한 multi-head attention과 동일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B05wr7aARcT"
      },
      "source": [
        "def decoder_module(inputs, encoder_outputs, model_dim, ffn_dim, heads):\n",
        "  masked_self_attn = sublayer_connection(inputs, \n",
        "                                         multi_head_attention(inputs, inputs, inputs, model_dim, heads, masked=True))\n",
        "  self_attn = sublayer_connection(masked_self_attn, \n",
        "                                         multi_head_attention(masked_self_attn, encoder_outputs, encoder_outputs, model_dim, heads, masked=True))\n",
        "  outputs = sublayer_connection(self_attn, feed_forward(self_attn, ffn_dim))\n",
        "  return outputs\n",
        "\n",
        "def decoder(inputs, encoders_outputs, model_dim, ffn_dim, heads, num_layers):\n",
        "  outputs = inputs\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_module(outputs, encoders_outputs, model_dim, ffn_dim, heads)\n",
        "\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtztlyUB1ERS"
      },
      "source": [
        "## 트랜스포머를 활용한 챗봇"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CGUIAzv6eWs"
      },
      "source": [
        "### konlpy 라이브러리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae0mHT49v5gy"
      },
      "source": [
        "*    한글을 처리하기 위해 konlpy 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Twitter\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import enum\n",
        "import os\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "#from configs import DEFINES\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3xTKlks1Yqnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install configs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fye0SdJOaPyB",
        "outputId": "a8a1fb97-d6be-4333-8302-33676ffde1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting configs\n",
            "  Downloading configs-3.0.3-py3-none-any.whl (7.1 kB)\n",
            "Installing collected packages: configs\n",
            "Successfully installed configs-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8yf75uG6hBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce094d3-2090-4a26-f2c5-7a4b157a097b"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUMXvK5H1G9H"
      },
      "source": [
        "### 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miXrjR316mNb"
      },
      "source": [
        "* 처리에 필요한 각종 변수 선언\n",
        "* filters에 해당되는 문자를 걸러주는 정규 표현식 컴파일\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMjn5PfE1GZR"
      },
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "\n",
        "filters = \"([~.,!?\\\"':;)(])\"\n",
        "PAD = '<PADDING>'\n",
        "STD = '<START>'\n",
        "END = '<END>'\n",
        "UNK = '<UNKNOWN>'\n",
        "\n",
        "PAD_INDEX = 0\n",
        "STD_INDEX = 1\n",
        "END_INDEX = 2\n",
        "UNK_INDEX = 3\n",
        "\n",
        "MARKER = [PAD, STD, END, UNK]\n",
        "CHANGE_FILTER = re.compile(filters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmRFuH2r6oNJ"
      },
      "source": [
        "* 주소에서 데이터를 가져오는 `load_data()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmrmdXkePWYb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(data_path):\n",
        "  data_df = pd.read_csv(data_path, header=0)\n",
        "  question, answer = list(data_df['Q']), list(data_df['A'])\n",
        "  train_inputs, eval_inputs, train_label, eval_label = train_test_split(question, answer,\n",
        "                                                                       test_size=0.33, random_state=111)\n",
        "  return train_inputs, train_label, eval_inputs, eval_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHuOJHPtPXqq"
      },
      "source": [
        "* 처리에 필요한 단어 사전을 생성하는 `load_vocab()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQL-AP06oSa"
      },
      "source": [
        "def load_vocabulary(data_path):\n",
        "  data_df = pd.read_csv(data_path, encoding='utf-8')\n",
        "  question, answer = list(data_df['Q']), list(data_df['A'])\n",
        "  if tokenize_as_morph:\n",
        "    question = prepro_like_morphlized(question)\n",
        "    answer = prepro_like_morphlized(answer)\n",
        "\n",
        "  data = []\n",
        "  data.extend(question)\n",
        "  data.extend(answer)\n",
        "  words = data_tokenizer(data)\n",
        "  words = list(set(words))\n",
        "  words[:0] = MARKER\n",
        "\n",
        "  char2idx = {char:idx for idx, char in enumerate(words)}\n",
        "  idx2char = {idx:char for idx, char in enumerate(words)}\n",
        "  return char2idx, idx2char, len(char2idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wYtpjv76r5q"
      },
      "source": [
        "* 문자열 데이터를 학습에 사용될 수 있도록 변현하는 `prepro_like_morphlized()` 함수 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bQ3FOva6tg6"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "def prepro_like_morphlized(data):\n",
        "    # 형태소 분석 모듈 객체를 생성합니다.\n",
        "\n",
        "    morph_analyzer = Okt()\n",
        "    # 형태소 토크나이즈 결과 문장을 받을 리스트를 생성합니다.\n",
        "    result_data = list()\n",
        "    # 데이터에 있는 매 문장에 대해 토크나이즈를 할 수 있도록 반복문을 선언합니다.\n",
        "    for seq in tqdm(data):\n",
        "        # Okt.morphs 함수를 통해 토크나이즈 된 리스트 객체를 받고 다시 공백문자를 기준으로 하여 문자열로 재구성 해줍니다.\n",
        "        morphlized_seq = \" \".join(morph_analyzer.morphs(seq.replace(' ', '')))\n",
        "        result_data.append(morphlized_seq)\n",
        "\n",
        "    return result_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhsVp4pWPTR3"
      },
      "source": [
        "* 단어 사전을 만들기 위해 단어들을 분리하는 `data_tokenizer()` 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otLI_RUfPR_g"
      },
      "source": [
        "def data_tokenizer(data):\n",
        "    # 토크나이징 해서 담을 배열 생성\n",
        "    words = []\n",
        "    for sentence in data:\n",
        "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
        "        # 위 필터와 같은 값들을 정규화 표현식을 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
        "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
        "        for word in sentence.split():\n",
        "            words.append(word)\n",
        "    # 토그나이징과 정규표현식을 통해 만들어진 값들을 넘겨 준다.\n",
        "    return [word for word in words if word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkKPA-Mx6uaC"
      },
      "source": [
        "* encoder의 입력을 구성하기 위한 함수 `enc_processing()` 선언\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-yeSThPGsa"
      },
      "source": [
        "# 인덱스화 할 value와 키가 워드이고 값이 인덱스인 딕셔너리를 받는다.\n",
        "def enc_processing(value, dictionary):\n",
        "    # 인덱스 값들을 가지고 있는 배열이다.(누적된다.)\n",
        "    sequences_input_index = []\n",
        "    # 하나의 인코딩 되는 문장의 길이를 가지고 있다.(누적된다.)\n",
        "    sequences_length = []\n",
        "    # 형태소 토크나이징 사용 유무\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "\n",
        "    # 한줄씩 불어온다.\n",
        "    for sequence in value:\n",
        "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
        "        # 정규화를 사용하여 필터에 들어 있는 값들을 \"\" 으로 치환 한다.\n",
        "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
        "        # 하나의 문장을 인코딩 할때 가지고 있기 위한 배열이다.\n",
        "        sequence_index = []\n",
        "        # 문장을 스페이스 단위로 자르고 있다.\n",
        "        for word in sequence.split():\n",
        "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고 그 값을 가져와 sequence_index에 추가한다.\n",
        "            if dictionary.get(word) is not None:\n",
        "                sequence_index.extend([dictionary[word]])\n",
        "            # 잘려진 단어가 딕셔너리에 존재 하지 않는 경우 이므로 UNK(2)를 넣어 준다.\n",
        "            else:\n",
        "                sequence_index.extend([dictionary[UNK]])\n",
        "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
        "        if len(sequence_index) > max_len:\n",
        "            sequence_index = sequence_index[:max_len]\n",
        "        # 하나의 문장에 길이를 넣어주고 있다.\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        # max_sequence_length보다 문장 길이가 \n",
        "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        # 인덱스화 되어 있는 값을 \n",
        "        # sequences_input_index에 넣어 준다.\n",
        "        sequences_input_index.append(sequence_index)\n",
        "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다. \n",
        "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
        "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.  \n",
        "    return np.asarray(sequences_input_index), sequences_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4mM57_FPIg7"
      },
      "source": [
        "* decoder의 입력을 구성하기 위한 함수 `dec_output_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX_NpcTq6vw6"
      },
      "source": [
        "def dec_output_processing(value, dictionary):\n",
        "    # 인덱스 값들을 가지고 있는 배열이다.(누적된다)\n",
        "    sequences_output_index = []\n",
        "    # 하나의 디코딩 입력 되는 문장의 길이를 가지고 있다.(누적된다)\n",
        "    sequences_length = []\n",
        "    # 형태소 토크나이징 사용 유무\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "    # 한줄씩 불어온다.\n",
        "    for sequence in value:\n",
        "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
        "        sequence_index = []\n",
        "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n",
        "        if len(sequence_index) > max_len:\n",
        "            sequence_index = sequence_index[:max_len]\n",
        "        sequences_length.append(len(sequence_index))\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        sequences_output_index.append(sequence_index)\n",
        "    return np.asarray(sequences_output_index), sequences_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otsTEt4FPLJX"
      },
      "source": [
        "* decoder의 출력을 구성하기 위한 함수 `dec_target_processing()` 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeP0PWHEPMma"
      },
      "source": [
        "def dec_target_processing(value, dictionary):\n",
        "    # 인덱스 값들을 가지고 있는 배열이다.(누적된다)\n",
        "    sequences_target_index = []\n",
        "    # 형태소 토크나이징 사용 유무\n",
        "    if tokenize_as_morph:\n",
        "        value = prepro_like_morphlized(value)\n",
        "    # 한줄씩 불어온다.\n",
        "    for sequence in value:\n",
        "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
        "        # 정규화를 사용하여 필터에 들어 있는 값들을 \"\" 으로 치환 한다.\n",
        "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
        "        # 문장에서 스페이스 단위별로 단어를 가져와서 \n",
        "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
        "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
        "        sequence_index = [dictionary[word] for word in sequence.split()]\n",
        "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
        "        # 그리고 END 토큰을 넣어 준다\n",
        "        if len(sequence_index) >= max_len:\n",
        "            sequence_index = sequence_index[:max_len-1] + [dictionary[END]]\n",
        "        else:\n",
        "            sequence_index += [dictionary[END]]\n",
        "        # max_sequence_length보다 문장 길이가 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
        "        sequence_index += (max_len - len(sequence_index)) * [dictionary[PAD]]\n",
        "        # 인덱스화 되어 있는 값을 sequences_target_index에 넣어 준다.\n",
        "        sequences_target_index.append(sequence_index)\n",
        "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다. \n",
        "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
        "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
        "    return np.asarray(sequences_target_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb9vVUng6xDq"
      },
      "source": [
        "* 모델에 데이터를 효율적으로 투입하도록 `train_input_fn()`, `eval_input_fn()` 함수 선언\n",
        "* `rearrange()`는 dataset 객체가 데이터를 어떻게 변형시킬지 정의해둔 함수\n",
        "* dataset.map은 rearrange 함수를 기반으로 데이터를 변형\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAlKV4xF62Uf"
      },
      "source": [
        "# 학습에 들어가 배치 데이터를 만드는 함수이다.\n",
        "def train_input_fn(train_input_enc, train_output_dec, train_target_dec, batch_size):\n",
        "    # Dataset을 생성하는 부분으로써 from_tensor_slices부분은 각각 한 문장으로 자른다고 보면 된다.\n",
        "    # train_input_enc, train_output_dec, train_target_dec 3개를 각각 한문장으로 나눈다.\n",
        "    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((train_input_enc, train_output_dec, train_target_dec))\n",
        "    # 전체 데이터를 썩는다.\n",
        "    dataset = dataset.shuffle(buffer_size=len(train_input_enc))\n",
        "    # 배치 인자 값이 없다면  에러를 발생 시킨다.\n",
        "    assert batch_size is not None, \"train batchSize must not be None\"\n",
        "    # from_tensor_slices를 통해 나눈것을 배치크기 만큼 묶어 준다.\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    # 데이터 각 요소에 대해서 rearrange 함수를 통해서 요소를 변환하여 맵으로 구성한다.\n",
        "    dataset = dataset.map(rearrange) \n",
        "    # repeat()함수에 원하는 에포크 수를 넣을수 있으면 아무 인자도 없다면 무한으로 이터레이터 된다.\n",
        "    dataset = dataset.repeat()\n",
        "    # make_one_shot_iterator를 통해 이터레이터를 만들어 준다.\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    # 이터레이터를 통해 다음 항목의 텐서 개체를 넘겨준다.\n",
        "    return iterator.get_next()\n",
        "\n",
        "# 평가에 들어가 배치 데이터를 만드는 함수이다.\n",
        "def eval_input_fn(eval_input_enc, eval_output_dec, eval_target_dec, batch_size):\n",
        "    # Dataset을 생성하는 부분으로써 from_tensor_slices부분은 각각 한 문장으로 자른다고 보면 된다.\n",
        "    # eval_input_enc, eval_output_dec, eval_target_dec 3개를 각각 한문장으로 나눈다.\n",
        "    dataset = tf.compat.v1.data.Dataset.from_tensor_slices((eval_input_enc, eval_output_dec, eval_target_dec))\n",
        "    # 전체 데이터를 섞는다.\n",
        "    dataset = dataset.shuffle(buffer_size=len(eval_input_enc))\n",
        "    # 배치 인자 값이 없다면  에러를 발생 시킨다.\n",
        "    assert batch_size is not None, \"eval batchSize must not be None\"\n",
        "    # from_tensor_slices를 통해 나눈것을 배치크기 만큼 묶어 준다.\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    # 데이터 각 요소에 대해서 rearrange 함수를 통해서 요소를 변환하여 맵으로 구성한다.\n",
        "    dataset = dataset.map(rearrange)\n",
        "    # repeat()함수에 원하는 에포크 수를 넣을수 있으면 아무 인자도 없다면 무한으로 이터레이터 된다.\n",
        "    # 평가이므로 1회만 동작 시킨다.\n",
        "    dataset = dataset.repeat(1)\n",
        "    # make_one_shot_iterator를 통해 이터레이터를 만들어 준다.\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    # 이터레이터를 통해 다음 항목의 텐서 개체를 넘겨준다.\n",
        "    return iterator.get_next()  \n",
        "\n",
        "def rearrange(input, output, target):\n",
        "    features = {\"input\": input, \"output\": output}\n",
        "    return features, target\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-GhUDN62xC"
      },
      "source": [
        "* 모델의 예측은 배열로 생성되기 때문에 이를 확인하기 위해선 문자열로 변환이 필요\n",
        "* 예측을 문자열로 변환해주는 `pred2string()` 함수 선언\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfwWXhb64Cc"
      },
      "source": [
        "# 인덱스를 스트링으로 변경하는 함수이다.\n",
        "# 바꾸고자 하는 인덱스 value와 인덱스를 키로 가지고 있고 값으로 단어를 가지고 있는 딕셔너리를 받는다.\n",
        "def pred2string(value, dictionary):\n",
        "    # 텍스트 문장을 보관할 배열을 선언한다.\n",
        "    sentence_string = []\n",
        "    is_finished = False\n",
        "\n",
        "    # 인덱스 배열 하나를 꺼내서 v에 넘겨준다.\n",
        "    for v in value:\n",
        "        # 딕셔너리에 있는 단어로 변경해서 배열에 담는다.\n",
        "        print(v['indexs'])\n",
        "        #for index in v['indexs']:\n",
        "        #    print(index)\n",
        "        sentence_string = [dictionary[index] for index in v['indexs']]\n",
        "\n",
        "    print(\"***********************\")\n",
        "    print(sentence_string)\n",
        "    print(\"***********************\")\n",
        "    answer = \"\"\n",
        "    # 패딩값도 담겨 있으므로 패딩은 모두 스페이스 처리 한다.\n",
        "    for word in sentence_string:\n",
        "        if word == END:\n",
        "          is_finished = True\n",
        "          break\n",
        "        \n",
        "        if word != PAD and word != END:\n",
        "          answer += word\n",
        "          answer += \" \"\n",
        "    return answer, is_finished\n",
        "\n",
        "def pred_next_string(value, dictionary):\n",
        "    # 텍스트 문장을 보관할 배열을 선언한다.\n",
        "    sentence_string = []\n",
        "    # 인덱스 배열 하나를 꺼내서 v에 넘겨준다.\n",
        "    for v in value:\n",
        "        # 딕셔너리에 있는 단어로 변경해서 배열에 담는다.\n",
        "        sentence_string = [dictionary[index] for index in v['indexs']]\n",
        "    \n",
        "    answer = \"\"\n",
        "    # 패딩값도 담겨 있으므로 패딩은 모두 스페이스 처리 한다.\n",
        "    for word in sentence_string:\n",
        "        if word not in PAD and word not in END:\n",
        "            answer += word\n",
        "            answer += \" \"\n",
        "    # 결과를 출력한다.\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwp9Nnwz7UoG"
      },
      "source": [
        "* 챗봇 데이터 URL: https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\n",
        "* 데이터 주소에서 데이터를 읽어들여 단어 사전과 사용 데이터 구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T536MdU7Taq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfaacc9-25a7-432a-9247-b85c13187b1d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tokenize_as_morph = True\n",
        "\n",
        "data_path =  '/content/ChatBotData.csv'\n",
        "\n",
        "char2idx, idx2char, len_vocab = load_vocabulary(data_path)\n",
        "train_input, train_label, eval_input, eval_label = load_data(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11823/11823 [00:39<00:00, 300.92it/s]\n",
            "100%|██████████| 11823/11823 [00:52<00:00, 225.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_input))\n",
        "print(len(train_label))\n",
        "print(len(eval_input))\n",
        "print(len(eval_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVMAgqtOISE2",
        "outputId": "598f0ba6-f6b3-4534-a20e-c6df63e35fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7921\n",
            "7921\n",
            "3902\n",
            "3902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "from functools import reduce\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "DATA_IN_PATH =  '/content/'\n",
        "\n",
        "data = pd.read_csv(DATA_IN_PATH + 'ChatBotData.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "nRl9bGiEZT26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVd7AOKinqn"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqLJ0a6r49yi"
      },
      "source": [
        "* 앞서 작성한 트랜스포머 모델을 결합해 학습에 사용할 모델을 구성함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNeeXoZginvj"
      },
      "source": [
        "def model(features, labels, mode, params):\n",
        "  TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "  EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "  PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "  position_encode = Positional_encoding(params['embedding_size'], params['max_len'])\n",
        "  if params['xavier_initializer']:\n",
        "    embeddings_initializer = 'glorot_normal'\n",
        "  else:\n",
        "    embeddings_initializer = 'uniform'\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(params['len_vocab'],\n",
        "                                        params['embedding_size'],\n",
        "                                        embeddings_initializer=embeddings_initializer)\n",
        "  \n",
        "  x_embedded_matrix = embedding(features['input']) + position_encode\n",
        "  y_embedded_matrix = embedding(features['output']) + position_encode\n",
        "\n",
        "  encoder_outputs = encoder(x_embedded_matrix, params['model_hidden_size'], params['ffn_hidden_size'],\n",
        "                           params['attention_head_size'], params['layer_size'])\n",
        "  \n",
        "  decoder_outputs = decoder(y_embedded_matrix, encoder_outputs, params['model_hidden_size'], \n",
        "                           params['ffn_hidden_size'], params['attention_head_size'], params['layer_size'])\n",
        "  \n",
        "  logits = tf.keras.layers.Dense(params['len_vocab'])(decoder_outputs)\n",
        "  predict = tf.argmax(logits, 2)\n",
        "\n",
        "  if PREDICT:\n",
        "    predictions = {'indexs': predict,'logits': logits}\n",
        "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  labels_ = tf.one_hot(labels, params['len_vocab'])\n",
        "  loss = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels_))\n",
        "\n",
        "  accuracy = tf.compat.v1.metrics.accuracy(labels=labels, predictions=predict)\n",
        "  #accuracy = tf.metrics.accuracy(labels=labels, predictions=predict, name='accOp')  \n",
        "\n",
        "  metrics = {'accuracy':accuracy}\n",
        "  tf.summary.scalar('accuracy', accuracy[1])\n",
        "\n",
        "  if EVAL:\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)\n",
        "  assert TRAIN\n",
        "\n",
        "  optimizer = tf.compat.v1.train.AdadeltaOptimizer(learning_rate=params['learning_rate'])\n",
        "  train_op = optimizer.minimize(loss, global_step=tf.compat.v1.train.get_global_step())\n",
        "  return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7PrLEWE1JCs"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy_Opm_A7DKC"
      },
      "source": [
        "*   필요한 각종 인자들을 설정\n",
        "*   인자에 따라 학습 결과가 달라질 수 있기 때문에 세심한 조정이 필요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKGYuqmH6_kj"
      },
      "source": [
        "max_len = 25\n",
        "epoch = 5000\n",
        "batch_size = 250\n",
        "embedding_size = 100\n",
        "model_hidden_size = 100\n",
        "ffn_hidden_size = 100\n",
        "attention_head_size = 100\n",
        "lr = 0.001\n",
        "layer_size = 3\n",
        "xavier_initializer = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaXalEy57ODq"
      },
      "source": [
        "*   앞서 선언한 processing 함수로 데이터를 모델에 투입할 수 있도록 가공\n",
        "*   평가 데이터에도 동일하게 가공"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlgWWIq1KSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbae39a-6cb1-49e6-f2d8-8d7dd52bf623"
      },
      "source": [
        "train_input_enc, train_input_enc_length = enc_processing(train_input, char2idx)\n",
        "train_output_dec, train_output_enc_length = dec_output_processing(train_label, char2idx)\n",
        "train_target_dec = dec_target_processing(train_label, char2idx)\n",
        "\n",
        "eval_input_enc, eval_input_enc_length = enc_processing(eval_input, char2idx)\n",
        "eval_output_dec, eval_output_enc_length = dec_output_processing(eval_input, char2idx)\n",
        "eval_target_dec = dec_target_processing(eval_label, char2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7921/7921 [00:26<00:00, 303.36it/s]\n",
            "100%|██████████| 7921/7921 [00:34<00:00, 231.63it/s]\n",
            "100%|██████████| 7921/7921 [00:34<00:00, 231.53it/s]\n",
            "100%|██████████| 3902/3902 [00:13<00:00, 294.70it/s]\n",
            "100%|██████████| 3902/3902 [00:13<00:00, 294.99it/s]\n",
            "100%|██████████| 3902/3902 [00:17<00:00, 228.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_input_enc.shape)\n",
        "print(train_output_dec.shape)\n",
        "print(train_target_dec.shape)\n",
        "print(eval_input_enc.shape)\n",
        "print(eval_output_dec.shape)\n",
        "print(eval_target_dec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Zg96b1G1qt",
        "outputId": "cae73050-a244-4d94-b0ab-908fcf31b0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7921, 25)\n",
            "(7921, 25)\n",
            "(7921, 25)\n",
            "(3902, 25)\n",
            "(3902, 25)\n",
            "(7921, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGgZzWs7Mr7"
      },
      "source": [
        "* 앞서 선언한 함수를 통해 모델을 선언하고 학습\n",
        "* `tf.estimator`를 사용해 간편하게 학습 모듈 구성\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9vjc3Ck7F4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e383f5-a09b-461f-c83a-363df826f09b"
      },
      "source": [
        "with strategy.scope():\n",
        "  transformer = tf.estimator.Estimator(\n",
        "      model_fn = model,\n",
        "      params = {'embedding_size':embedding_size,\n",
        "                'model_hidden_size':model_hidden_size,\n",
        "                'ffn_hidden_size':ffn_hidden_size,\n",
        "                'attention_head_size':attention_head_size,\n",
        "                'learning_rate':lr,\n",
        "                'len_vocab':len_vocab,\n",
        "                'layer_size':layer_size,\n",
        "                'max_len':max_len,\n",
        "                'xavier_initializer':xavier_initializer}\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpzrd046ls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl_pwUiw7INZ"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COO-0PcS7Hy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140d886d-9e8b-49c7-c0fb-09f78a6eb248"
      },
      "source": [
        "transformer.train(input_fn=lambda: train_input_fn(train_input_enc, train_output_dec, train_target_dec, batch_size), steps=epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1161: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f6e5599d350>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = transformer.evaluate(input_fn=lambda: eval_input_fn(eval_input_enc, eval_output_dec, eval_target_dec,  batch_size))"
      ],
      "metadata": {
        "id": "mQxHm2qsrBb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nEVAL set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RowbKUByrBzl",
        "outputId": "ee82ca44-1491-4068-c117-e434a4efeed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EVAL set accuracy: 0.766\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNcrVf2z1LSM"
      },
      "source": [
        "### 예측"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5lY9DrW8eSK"
      },
      "source": [
        "* 학습한 모델을 사용해 챗봇을 사용\n",
        "* 예측 결과를 문자열로 변환할 때는 앞서 선언한 `pred2string()` 함수를 이용\n",
        "* 입력에 대한 응답이 생성되는 것을 확인할 수 있음\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IQaBx4Qw8J"
      },
      "source": [
        "def chatbot(sentence):\n",
        "  pred_input_enc, pred_input_enc_length = enc_processing([sentence], char2idx)\n",
        "  pred_output_dec, pred_output_dec_length = dec_output_processing([\"\"], char2idx)\n",
        "  pred_target_dec = dec_target_processing([\"\"], char2idx)\n",
        "\n",
        "  for i in range(max_len):\n",
        "    if i > 0:\n",
        "      pred_output_dec, pred_output_dec_length = dec_output_processing([answer], char2idx)\n",
        "      pred_target_dec = dec_target_processing([answer], char2idx)\n",
        "\n",
        "    predictions = transformer.predict(input_fn=lambda: eval_input_fn(pred_input_enc, pred_output_dec, pred_target_dec,  1))\n",
        "\n",
        "    answer, finished = pred2string(predictions, idx2char)\n",
        "\n",
        "    if finished:\n",
        "      break\n",
        "\n",
        "  return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjHZKvJ31MAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "66d14c0f-e54b-4502-a42b-f4591d75f870"
      },
      "source": [
        "chatbot(\"안녕?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1179.50it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 905.31it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 3469.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "***********************\n",
            "['<END>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>']\n",
            "***********************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mjRZwyLQ_gP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AJCsXRTqJx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M8mfoUfeAWQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5mrdGRaem6v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}